{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1: Imports + params\n",
        "from datetime import timedelta\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import GBTRegressor, LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "forecast_days = 30\n",
        "horizon_valid_days = 14\n",
        "model_version = \"gbt_risk_v2\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "29cb2d59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 2: Base data hygiene\n",
        "base = (\n",
        "    spark.table(\"gold_country_risk_daily\")\n",
        "    .select(\"iso3\", \"as_of_date\", \"risk_score\", \"funding_gap_ratio\", \"in_need_ratio\", \"flood_area_pct\")\n",
        "    .withColumn(\"as_of_date\", F.to_date(\"as_of_date\"))\n",
        "    .withColumn(\"risk_score\", F.col(\"risk_score\").cast(\"double\"))\n",
        "    .withColumn(\"funding_gap_ratio\", F.col(\"funding_gap_ratio\").cast(\"double\"))\n",
        "    .withColumn(\"in_need_ratio\", F.col(\"in_need_ratio\").cast(\"double\"))\n",
        "    .withColumn(\"flood_area_pct\", F.col(\"flood_area_pct\").cast(\"double\"))\n",
        "    .filter(F.col(\"iso3\").rlike(\"^[A-Z]{3}$\"))\n",
        "    .filter(F.col(\"as_of_date\").isNotNull())\n",
        "    .filter(F.col(\"risk_score\").isNotNull())\n",
        ")\n",
        "display(base.limit(20))\n",
        "print(\"rows:\", base.count())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5a1bd00a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 3: Feature engineering + robust split (auto lag/no-lag)\n",
        "source_table = \"workspace.default.gold_country_risk_history\"\n",
        "try:\n",
        "    raw = spark.table(source_table)\n",
        "except Exception:\n",
        "    source_table = \"workspace.default.gold_country_risk_daily\"\n",
        "    raw = spark.table(source_table)\n",
        "\n",
        "base = (\n",
        "    raw\n",
        "    .select(\n",
        "        \"iso3\", \"as_of_date\", \"risk_score\",\n",
        "        \"flood_area_pct\", \"in_need_ratio\", \"funding_gap_ratio\"\n",
        "    )\n",
        "    .withColumn(\"as_of_date\", F.to_date(\"as_of_date\"))\n",
        "    .withColumn(\"risk_score\", F.col(\"risk_score\").cast(\"double\"))\n",
        "    .withColumn(\"flood_area_pct\", F.col(\"flood_area_pct\").cast(\"double\"))\n",
        "    .withColumn(\"in_need_ratio\", F.col(\"in_need_ratio\").cast(\"double\"))\n",
        "    .withColumn(\"funding_gap_ratio\", F.col(\"funding_gap_ratio\").cast(\"double\"))\n",
        "    .filter(F.col(\"iso3\").rlike(\"^[A-Z]{3}$\"))\n",
        "    .filter(F.col(\"as_of_date\").isNotNull())\n",
        "    .filter(F.col(\"risk_score\").isNotNull())\n",
        ")\n",
        "\n",
        "base_rows = base.count()\n",
        "distinct_dates = base.select(\"as_of_date\").distinct().count()\n",
        "print(\"source_table:\", source_table)\n",
        "print(\"base rows:\", base_rows)\n",
        "print(\"distinct dates:\", distinct_dates)\n",
        "base.groupBy(\"iso3\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.col(\"n\").asc()).show(10, False)\n",
        "\n",
        "if base_rows == 0:\n",
        "    raise ValueError(\"No base rows available in source table.\")\n",
        "\n",
        "# Need at least 8 dates to make lag7 and rolling stats meaningful.\n",
        "use_lag_features = distinct_dates >= 8\n",
        "print(\"use_lag_features:\", use_lag_features)\n",
        "\n",
        "if use_lag_features:\n",
        "    w = Window.partitionBy(\"iso3\").orderBy(\"as_of_date\")\n",
        "    feat = (\n",
        "        base\n",
        "        .withColumn(\"risk_lag1\", F.lag(\"risk_score\", 1).over(w))\n",
        "        .withColumn(\"risk_lag7\", F.lag(\"risk_score\", 7).over(w))\n",
        "        .withColumn(\"risk_ma7\", F.avg(\"risk_score\").over(w.rowsBetween(-7, -1)))\n",
        "        .withColumn(\"risk_std7\", F.coalesce(F.stddev(\"risk_score\").over(w.rowsBetween(-7, -1)), F.lit(0.0)))\n",
        "        .withColumn(\"day_of_week\", F.dayofweek(\"as_of_date\").cast(\"double\"))\n",
        "        .withColumn(\"month\", F.month(\"as_of_date\").cast(\"double\"))\n",
        "        .withColumn(\"flood_area_pct\", F.coalesce(F.col(\"flood_area_pct\"), F.lit(0.0)))\n",
        "        .withColumn(\"in_need_ratio\", F.coalesce(F.col(\"in_need_ratio\"), F.lit(0.0)))\n",
        "        .withColumn(\"funding_gap_ratio\", F.coalesce(F.col(\"funding_gap_ratio\"), F.lit(0.0)))\n",
        "        .withColumn(\"risk_lag7\", F.coalesce(F.col(\"risk_lag7\"), F.col(\"risk_lag1\")))\n",
        "        .withColumn(\"risk_ma7\", F.coalesce(F.col(\"risk_ma7\"), F.col(\"risk_lag1\")))\n",
        "        .filter(F.col(\"risk_lag1\").isNotNull())\n",
        "    )\n",
        "    feature_cols = [\n",
        "        \"risk_lag1\", \"risk_lag7\", \"risk_ma7\", \"risk_std7\",\n",
        "        \"funding_gap_ratio\", \"in_need_ratio\", \"flood_area_pct\",\n",
        "        \"day_of_week\", \"month\"\n",
        "    ]\n",
        "else:\n",
        "    # Fallback for short history (e.g., single-date snapshots).\n",
        "    feat = (\n",
        "        base\n",
        "        .withColumn(\"day_of_week\", F.dayofweek(\"as_of_date\").cast(\"double\"))\n",
        "        .withColumn(\"month\", F.month(\"as_of_date\").cast(\"double\"))\n",
        "        .withColumn(\"flood_area_pct\", F.coalesce(F.col(\"flood_area_pct\"), F.lit(0.0)))\n",
        "        .withColumn(\"in_need_ratio\", F.coalesce(F.col(\"in_need_ratio\"), F.lit(0.0)))\n",
        "        .withColumn(\"funding_gap_ratio\", F.coalesce(F.col(\"funding_gap_ratio\"), F.lit(0.0)))\n",
        "    )\n",
        "    feature_cols = [\n",
        "        \"funding_gap_ratio\", \"in_need_ratio\", \"flood_area_pct\",\n",
        "        \"day_of_week\", \"month\"\n",
        "    ]\n",
        "\n",
        "feat_count = feat.count()\n",
        "print(\"feat rows:\", feat_count)\n",
        "if feat_count == 0:\n",
        "    raise ValueError(\"No usable rows after feature engineering.\")\n",
        "\n",
        "max_date = feat.agg(F.max(\"as_of_date\").alias(\"mx\")).first()[\"mx\"]\n",
        "if max_date is None:\n",
        "    raise ValueError(\"No max_date found from features.\")\n",
        "\n",
        "# If date coverage is too small for a temporal split, do random split.\n",
        "if distinct_dates <= horizon_valid_days:\n",
        "    train_df, valid_df = feat.randomSplit([0.8, 0.2], seed=42)\n",
        "    split_date = None\n",
        "else:\n",
        "    split_date = max_date - timedelta(days=horizon_valid_days)\n",
        "    train_df = feat.filter(F.col(\"as_of_date\") <= F.lit(split_date))\n",
        "    valid_df = feat.filter(F.col(\"as_of_date\") > F.lit(split_date))\n",
        "\n",
        "train_count = train_df.count()\n",
        "valid_count = valid_df.count()\n",
        "\n",
        "if valid_count == 0:\n",
        "    train_df, valid_df = feat.randomSplit([0.8, 0.2], seed=42)\n",
        "    train_count = train_df.count()\n",
        "    valid_count = valid_df.count()\n",
        "\n",
        "if train_count == 0 or valid_count == 0:\n",
        "    raise ValueError(f\"Insufficient train/valid rows. train={train_count}, valid={valid_count}\")\n",
        "\n",
        "print(\"max_date:\", max_date, \"split_date:\", split_date)\n",
        "print(\"feature_cols:\", feature_cols)\n",
        "print(\"train rows:\", train_count, \"valid rows:\", valid_count)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a91522fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 4: Train ML model with fallback + evaluation\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "gbt = GBTRegressor(\n",
        "    labelCol=\"risk_score\",\n",
        "    featuresCol=\"features\",\n",
        "    predictionCol=\"prediction\",\n",
        "    maxIter=120,\n",
        "    maxDepth=5,\n",
        "    stepSize=0.05,   # learning-rate style control (smaller = slower, steadier updates)\n",
        "    subsamplingRate=0.8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "lr = LinearRegression(\n",
        "    labelCol=\"risk_score\",\n",
        "    featuresCol=\"features\",\n",
        "    predictionCol=\"prediction\",\n",
        "    maxIter=200,\n",
        "    regParam=0.05,\n",
        "    elasticNetParam=0.2\n",
        ")\n",
        "\n",
        "train_count = train_df.count()\n",
        "if train_count < 30:\n",
        "    raise ValueError(f\"Too few training rows for ML model. train rows={train_count}\")\n",
        "\n",
        "model_name = \"gbt\"\n",
        "try:\n",
        "    model = Pipeline(stages=[assembler, gbt]).fit(train_df)\n",
        "except Exception as e:\n",
        "    print(\"GBT fit failed; falling back to LinearRegression:\", str(e)[:400])\n",
        "    model = Pipeline(stages=[assembler, lr]).fit(train_df)\n",
        "    model_name = \"linear_regression\"\n",
        "\n",
        "valid_pred = model.transform(valid_df)\n",
        "\n",
        "# Clamp predictions into risk range\n",
        "valid_pred = valid_pred.withColumn(\n",
        "    \"prediction\",\n",
        "    F.when(F.col(\"prediction\") < 0, F.lit(0.0))\n",
        "     .when(F.col(\"prediction\") > 1, F.lit(1.0))\n",
        "     .otherwise(F.col(\"prediction\"))\n",
        ")\n",
        "\n",
        "rmse = RegressionEvaluator(labelCol=\"risk_score\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(valid_pred)\n",
        "mae = RegressionEvaluator(labelCol=\"risk_score\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(valid_pred)\n",
        "\n",
        "print(\"model_used:\", model_name)\n",
        "print(\"validation rmse:\", round(rmse, 5), \"mae:\", round(mae, 5))\n",
        "\n",
        "display(valid_pred.select(\"iso3\", \"as_of_date\", \"risk_score\", \"prediction\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ffc1dcd2"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}